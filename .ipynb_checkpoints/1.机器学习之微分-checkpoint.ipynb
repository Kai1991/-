{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 大纲\n",
    "\n",
    "* 1.微分的思想与基本方法\n",
    "    * 1.1 微分的核心思想：函数逼近\n",
    "    * 1.2 微积分的基本语言：极限论\n",
    "    * 1.3 微分的基本方法：求导数\n",
    "    * 1.4 从线性逼近到多项式逼近：泰勒级数\n",
    "    * 1.5 从低维到高维：多元函数的梯度\n",
    "* 2.梯度下降法和牛顿法\n",
    "    * 2.1随机梯度下降法\n",
    "    * 2.2随机梯度下降法的问题与挑战\n",
    "    * 2.3随机梯度下降法的改进算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.微分的思想与基本方法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.1 微分的核心思想：函数逼近\n",
    "\n",
    "微分学的核心思想是：使用熟悉且简单的函数对复杂的函数进行局部逼近\n",
    "\n",
    "常用的逼近手段有：\n",
    "\n",
    "* 线性函数：函数的一阶导数\n",
    "* 多项式函数：泰勒级数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.2 微分学基础语言：极限论\n",
    "\n",
    "极限的表达方式：\n",
    "\n",
    "* 自然语言：当x趋向于a时，f(x)的L\n",
    "* 数学符号：$\\lim_{x\\to a} = L$\n",
    "\n",
    "无穷小：一般把趋于0的极限为无穷小\n",
    "\n",
    "两边夹定理：如果f(x) < g(x) < h(x) 且三个函数在a点出都有极限，那么：$\\lim_{x\\to a} f(x) < \\lim_{x\\to a} g(x) < \\lim_{x\\to a} h(x) $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.3微分学基本手法： 求导数\n",
    "\n",
    "一阶导数：$f(x)^ `= \\lim_{\\Delta \\to 0}  {f(x +  \\Delta ) - f(x) \\over \\Delta} $\n",
    "\n",
    "集合意义： 用支线逼近曲线\n",
    "\n",
    "代数意义：用线性函数去逼近复杂的函数\n",
    "\n",
    "对函数进行线性逼近：$f(x_0 + \\Delta)= f(x_0) + \\Delta {d f(x) \\over dx } + o(\\Delta)$\n",
    "\n",
    "常见的导数：\n",
    "* 多项式函数：$ {d X^n \\over dx } = nX^{n-1} $\n",
    "* 三角函数：$ {d sin(x) \\over dx } = cos(x) $\n",
    "* 指数函数：$ {d e^x \\over dx } = e^x $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.4 从线性逼近到多项式逼近：泰勒级数\n",
    "\n",
    "n阶导数的导数为n+1阶\n",
    "\n",
    "泰勒级数：利用n阶导数对函数进行高阶逼近\n",
    "\n",
    "泰勒级数公式： 如果一个函数f(x)是n阶可微的函数，那么 $f(x_0 + \\Delta)= f(x_0) + \\Delta {d f(x) \\over dx } +  \\Delta^2 {d f(x)_2 \\over dx} + \\Delta^3 {d f(x)_3 \\over dx} +  ...  + o(\\Delta)$\n",
    "\n",
    "牛顿法 ：利用n=2的泰勒级数逼近函数"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1.5 从低维到高维：多元函数的梯度\n",
    "\n",
    "偏导数：对于多元函数 $ f(x_1,x_2) $ ,则这个函数关于$x_1$和$x_2$的偏导数为：\n",
    "\n",
    "* $ {\\delta f(x_1,x_2) \\over \\delta x_1 } = \\lim_{\\Delta \\to 0}  {f(x_1 +  \\Delta,x_2 ) - f(x_1,x_2) \\over \\Delta} $ \n",
    "* $ {\\delta f(x_1,x_2) \\over \\delta x_2 } = \\lim_{\\Delta \\to 0}  {f(x_1,x_2 + \\Delta) - f(x_1,x_2) \\over \\Delta} $ \n",
    "\n",
    "为什么要讲偏导数？ 因为偏导数组成梯度。梯度是什么呢？ 一上面偏函数使用的多远函数为例\n",
    "\n",
    "梯度： $ \\nabla f(x_1,x_2) = ({\\delta f(x_1,x_2) \\over \\delta x_1 },{\\delta f(x_1,x_2) \\over \\delta x_2 })^T $ 就是这个函数的偏导数的列向量\n",
    "\n",
    "梯度的代数含义：任意方向的偏导数都可以用梯度表示\n",
    "\n",
    "梯度的集合意义：梯度方向是函数增长最快的方向"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.梯度下降法和牛顿法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.1随机梯度下降法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "梯度下降法：如果$f(\\theta)$ 是一个多元函数，在$\\theta_0$处做线性逼近 （ $f(\\theta_0 + \\Delta^T)= f(\\theta_0) + \\Delta^T {d f(\\theta) \\over dx } + o(| \\Delta^T |)$ ）\n",
    "\n",
    "这个线性毕竟不能告诉我们极小值在什么地方，它只能告诉我们极值点在什么方向， 所以我们只能选取一个比较小的步伐（学名：学习率$ \\eta$）反方向走下去，并且得到梯度下降的序列：\n",
    "* $ \\theta_n = \\theta_{n-1} - \\eta \\nabla f(\\theta_{n-1}) $ \n",
    "\n",
    "这里主要讲的事梯度下降算法，同时也会对比讲一下，牛顿法。\n",
    "\n",
    "梯度下降算法是对函数进行一阶逼近，而牛顿法是对函数进行二阶逼近，并直接预估函数的最小值"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.2 梯度下降法的问题与挑战\n",
    "\n",
    "* 1. 当样本大时，计算梯度非常耗时\n",
    "* 2. 学习率不好选择，选择小了收敛慢，选择大了不收敛。具体问题要具体分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2.3随机梯度下降法的改进算法\n",
    "见另外一篇总结"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
